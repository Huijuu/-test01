{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function # In Python2, print is a statement, in Python3, print is a function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Google Trend(Char only)\n",
    "https://www.google.com.tw/trends/fetchComponent?q=%2Fm%2F016c3c&date=now%207-d&cid=TIMESERIES_GRAPH_0&export=5&w=0&h=0&nhf=1\n",
    "https://www.google.com.tw/trends/explore#q=%E4%B9%9D%E4%BB%BD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# from bs4 import BeautifulSoup\n",
    "# import json\n",
    "# import time\n",
    "\n",
    "# res = requests.get('https://www.google.com.tw/trends/trendsReport?hl=zh-TW&q=%E4%B9%9D%E4%BB%BD&tz=Etc%2FGMT-8&content=1')\n",
    "# soup = BeautifulSoup(res.text,'html5lib')\n",
    "# res.encoding = 'utf-8'\n",
    "\n",
    "# datas = soup.select('#TIMESERIES_GRAPH_0')#[0]  #抓id='TIMESERIES_GRAPH_0'的內容\n",
    "# # print(type(datas))  #<class 'bs4.element.Tag'>\n",
    "# # print(len(datas)) \n",
    "# print(datas)\n",
    "\n",
    "# time.sleep(3)  #避免被擋掉，小睡一會兒\n",
    "\n",
    "# data_sc = [s.extract() for s in datas.select('script')] #只留<script>裡的資料(包含)\n",
    "# # print(data_sc)  #<class 'bs4.element.Tag'>\n",
    "\n",
    "# print(data_sc[0].text)\n",
    "\n",
    "# # article_dict = {}\n",
    "# # article_dict = data_sc[0]\n",
    "# # print(article_dict[0])\n",
    "\n",
    "\n",
    "# # data_n = [s.extract() for s in datas.select('/n')]\n",
    "# # print(len(data_n))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # total_data = int(datas1[0].select('rows')[1]['href']\\\n",
    "# #              .split('index')[1]\\\n",
    "# #              .split('.')[0]) + 1\n",
    "\n",
    "\n",
    "# # # doc = json.loads(res.text)\n",
    "# # # datas = doc['LM_Data']\n",
    "\n",
    "# # # print(doc['LM_Data']) #印出陣列list[]\n",
    "# # # print(datas[0]['LandMark_Name']) #印出list[0]中key值:LandMark_Name\n",
    "\n",
    "# # # for i in range(len(datas)):\n",
    "# #      print(datas[i]['LandMark_Name'])\n",
    "\n",
    "\n",
    "# # datas2 = datas1.split('\\n')\n",
    "# # print(datas2[0])\n",
    "# # doc = json.loads(res.text)\n",
    "# # datas = doc['chartData']\n",
    "\n",
    "# # print(doc['chartData']) #印出陣列list[]\n",
    "# # # print(datas[0]['LandMark_Name']) #印出list[0]中key值:LandMark_Name\n",
    "\n",
    "\n",
    "# # for i in range(len(datas)):\n",
    "# #     print(datas[i]['f'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Google 台北推薦景點\n",
    "https://www.google.com.tw/search?q=%E5%8F%B0%E5%8C%97%E6%99%AF%E9%BB%9E&oq=%E5%8F%B0%E5%8C%97%E6%99%AF%E9%BB%9E&aqs=chrome..69i57.3127j0j1&sourceid=chrome&ie=UTF-8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "國立故宮博物院\n",
      "，中正紀念堂\n",
      "，台北101\n",
      "，艋舺龍山寺\n",
      "，西門町\n",
      "，士林夜市\n",
      "，國立國父紀念館\n",
      "，臺北市立美術館\n",
      "，臺北市立動物園\n",
      "，臺北車站\n",
      "，袖珍博物館\n",
      "，國立臺灣博物館\n",
      "，行天宮\n",
      "，松山文化創意園區\n",
      "，順益台灣原住民博物館\n",
      "，國立歷史博物館\n",
      "，國軍歷史文物館\n",
      "，郵政博物館\n",
      "，臺北小巨蛋\n",
      "，中影文化城\n",
      "，臺北市立天母棒球場\n",
      "，臺北水道水源地\n",
      "，華山1914文化創意產業園區\n",
      "，國家圖書館\n",
      "，光華商場\n",
      "，大安森林公園\n",
      "，微風廣場\n",
      "，美麗華百樂園\n",
      "，圓山大飯店\n",
      "，迪化街\n",
      "，國立臺灣大學人類學博物館\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "res = requests.get('https://www.google.com.tw/search?q=%E5%8F%B0%E5%8C%97%E6%99%AF%E9%BB%9E&oq=%E5%8F%B0%E5%8C%97%E6%99%AF%E9%BB%9E&aqs=chrome..69i57.3127j0j1&sourceid=chrome&ie=UTF-8')\n",
    "soup = BeautifulSoup(res.text,'html5lib') \n",
    "\n",
    "# data_id = soup.select('#_vBb')\n",
    "# print(data_id[0].text)\n",
    "\n",
    "\n",
    "data_span = soup.select('span._G0d')\n",
    "for i in range(0,len(data_span)):\n",
    "    print(data_span[i].text.strip())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. 台北熱門景點(非來不可網站)\n",
    "http://www.flbk.com.tw/Top_LM1.aspx?city=2&search=%E5%8F%B0%E5%8C%97"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 【將網頁上景點標題抓下.get】"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from bs4 import BeautifulSoup\n",
    "\n",
    "# res = requests.get('http://www.flbk.com.tw/Top_LM1.aspx?city=2&search=%E5%8F%B0%E5%8C%97')\n",
    "# soup = BeautifulSoup(res.text,'html5lib') \n",
    "# res.encoding = 'utf-8'\n",
    "\n",
    "# # print(res.text)\n",
    "# # datas = soup.select('h3')[0].text\n",
    "# # print(data)\n",
    "\n",
    "# datas = soup.select('div.infoContent')\n",
    "# for one in datas:\n",
    "#     print(one.select('h3')[0].text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 【JSON格式資料取值參考]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "音樂\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import requests\n",
    "r=requests.get('http://cloud.culture.tw/frontsite/trans/SearchShowAction.do?method=doFindAllTypeJ')\n",
    "doc=json.loads(r.text)\n",
    "print(doc[0]['categoryName'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 【將網頁上使用 Java Script 方法之景點標題抓下.post】 & 截取 JSON 格式資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from bs4 import BeautifulSoup\n",
    "# import json\n",
    "# dic ={\n",
    "#     'City':'2',\n",
    "#     'Type':'1',\n",
    "#     'PageStr':'2',\n",
    "#     'Search':'台北',\n",
    "#     'seed': '25'}\n",
    "\n",
    "# res = requests.post('http://www.flbk.com.tw/Api/Top/GetLMList.aspx', data=dic)\n",
    "# # print(res.text)\n",
    "\n",
    "# soup = BeautifulSoup(res.text,'html5lib') \n",
    "# res.encoding = 'utf-8'\n",
    "\n",
    "# doc = json.loads(res.text)\n",
    "# datas = doc['LM_Data']\n",
    "\n",
    "# # print(doc['LM_Data']) #印出陣列list[]\n",
    "# # print(datas[0]['LandMark_Name']) #印出list[0]中key值:LandMark_Name\n",
    "\n",
    "# for i in range(len(datas)):\n",
    "#     print(datas[i]['LandMark_Name'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "國立故宮博物院\n",
      "中正紀念堂\n",
      "台北101\n",
      "陽明山國家公園\n",
      "白石湖吊橋\n",
      "花博公園\n",
      "士林夜市\n",
      "五分埔\n",
      "竹子湖\n",
      "貓空纜車\n",
      "采泥藝術中心\n",
      "陽明山平菁街\n",
      "陽明山花卉試驗中心\n",
      "台北花卉村\n",
      "台北車站\n",
      "國立故宮博物院\n",
      "中正紀念堂\n",
      "台北101\n",
      "陽明山國家公園\n",
      "白石湖吊橋\n",
      "花博公園\n",
      "士林夜市\n",
      "五分埔\n",
      "竹子湖\n",
      "貓空纜車\n",
      "采泥藝術中心\n",
      "陽明山平菁街\n",
      "陽明山花卉試驗中心\n",
      "台北花卉村\n",
      "台北車站\n",
      "華山1914文化創意產業園區\n",
      "國父紀念館\n",
      "二格山系-仙跡岩親山步道\n",
      "松山文創園區\n",
      "士林官邸公園\n",
      "原住民風味館\n",
      "松山機場觀景台\n",
      "陽明書屋\n",
      "臺北小巨蛋\n",
      "北投焚化廠觀景台\n",
      "寧夏夜市\n",
      "永康街\n",
      "饒河街觀光夜市\n",
      "西門町商圈\n",
      "新光三越台北信義新天地\n",
      "大稻埕碼頭\n",
      "地熱谷\n",
      "台北市立動物園(木柵動物園)\n",
      "臺北忠烈祠\n",
      "陽明山冷水坑\n",
      "五指山系-劍潭山親山步道\n",
      "南港山系-更寮古道親山步道\n",
      "圓山大飯店\n",
      "擎天崗\n",
      "青年公園\n",
      "師大夜市\n",
      "南機場彰化肉丸\n",
      "THE WALL(活動)\n",
      "台北奧萬大\n",
      "統一阪急百貨台北店\n",
      "萬華龍山寺\n",
      "大安森林公園\n",
      "南港山系－象山親山步道\n",
      "袖珍博物館\n",
      "國立歷史博物館\n",
      "國立臺灣博物館\n",
      "信義公民會館（四四南村）\n",
      "彩虹橋\n",
      "內雙溪自然公園\n",
      "臺大公館商圈\n",
      "迪化街-年貨大街\n",
      "華西街觀光夜市(萬華夜市)\n",
      "美麗華百樂園\n",
      "千島湖\n",
      "橡子共和國(信義店)\n",
      "台北霞海城隍廟\n",
      "行天宮\n",
      "二二八和平公園\n",
      "林安泰古厝民俗文物館\n",
      "關渡自然公園\n",
      "臺北孔廟\n",
      "二格山系-指南宮貓空親山步道\n",
      "大佳河濱公園\n",
      "新生公園\n",
      "延平河濱公園\n",
      "大湖公園\n",
      "微風台北車站\n",
      "夢幻湖\n",
      "台北國際藝術村\n",
      "千蝶谷昆蟲生態農場\n",
      "新北投溫泉區\n",
      "陽明山溫泉區\n",
      "台北探索館\n",
      "北投溫泉博物館\n",
      "臺北市立美術館\n",
      "西門紅樓\n",
      "自來水博物館\n",
      "兩廳院 (國家戲劇院&國家音樂廳)\n",
      "臺北故事館\n",
      "臺北市立天文科學教育館\n",
      "寶藏巖國際藝術村\n",
      "台北市立兒童新樂園\n",
      "內湖劍南山\n",
      "裸市集\n",
      "中強公園\n",
      "臺北當代藝術館\n",
      "陽明山中山樓\n",
      "臺北啤酒工廠\n",
      "國立臺灣科學教育館\n",
      "北投文物館\n",
      "松山慈祐宮\n",
      "總統府\n",
      "臺北偶戲館\n",
      "清真寺\n",
      "臺北市客家文化主題公園\n",
      "藍色公路-大稻埕\n",
      "台北植物園\n",
      "國立臺灣博物館 (土銀展示館)\n",
      "白沙灣水域遊憩區\n",
      "北投圖書館\n",
      "大龍峒保安宮\n",
      "臺北市鄉土教育中心(剝皮寮歷史街區)\n",
      "中山堂\n",
      "胡適紀念館\n",
      "郵政博物館\n",
      "鐵觀音包種茶研發推廣中心\n",
      "蝴蝶宮‧昆蟲科學博物館\n",
      "國史館\n",
      "臺灣大學\n",
      "國家文創禮品店\n",
      "台灣總督府交通局鐵道部\n",
      "臺北世貿中心\n",
      "美堤河濱公園\n",
      "齊東詩舍\n",
      "BabyBoss職業體驗任意城\n",
      "關渡宮\n",
      "指南宮\n",
      "林語堂故居\n",
      "芝山文化生態綠園(芝山岩展示館)\n",
      "順益臺灣原住民博物館\n",
      "艋舺青山宮\n",
      "錢穆故居\n",
      "關渡美術館\n",
      "榮星公園\n",
      "貴子坑水土保持教學園區\n",
      "國立臺灣藝術教育館\n",
      "台北國軍藝文中心\n",
      "蒙藏文化中心\n",
      "碧山巖開漳聖王廟\n",
      "北投兒童樂園\n",
      "艋舺清水巖\n",
      "樹火紀念紙博物館\n",
      "台灣昆蟲館\n",
      "海關博物館\n",
      "國軍歷史文物館\n",
      "菸酒專賣局\n",
      "臺北市立社會教育館\n",
      "台灣精品館\n",
      "太原五百完人紀念建築群\n",
      "糖廍文化園區\n",
      "彩虹河濱公園\n",
      "非來不可活動總部\n",
      "松壽廣場公園\n",
      "NoData & End!\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "\n",
    "# 將沒有JS的網頁內容抓下\n",
    "res = requests.get('http://www.flbk.com.tw/Top_LM1.aspx?city=2&search=%E5%8F%B0%E5%8C%97')\n",
    "soup = BeautifulSoup(res.text,'html5lib') \n",
    "res.encoding = 'utf-8'\n",
    "\n",
    "# print(res.text)\n",
    "# datas = soup.select('h3')[0].text\n",
    "# print(data)\n",
    "\n",
    "datas = soup.select('div.infoContent')\n",
    "for one in datas:\n",
    "    print(one.select('h3')[0].text)\n",
    "\n",
    "# 將JS的網頁內容抓下，因有11張分頁，雇用\"\"迴圈\"\"\n",
    "count = 2\n",
    "for count in xrange(1,50):\n",
    "    try:\n",
    "        dic ={\n",
    "            'City':'2',\n",
    "            'Type':'1',\n",
    "            'PageStr': count,\n",
    "            'Search':'台北',\n",
    "            'seed':'25'\n",
    "        }\n",
    "        res = requests.post('http://www.flbk.com.tw/Api/Top/GetLMList.aspx', data=dic)\n",
    "        soup = BeautifulSoup(res.text,'html5lib') \n",
    "        doc = json.loads(res.text)\n",
    "        datas = doc['LM_Data']\n",
    "\n",
    "        for i in range(len(datas)):\n",
    "            print(datas[i]['LandMark_Name'])\n",
    "        count += 1\n",
    "    except:\n",
    "        print(\"NoData & End!\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chrome driver & Selenium 測試程式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Python3.5\n",
    "# OS: Windows7\n",
    "# IDE: PyCharm\n",
    "\n",
    "from selenium import webdriver\n",
    "import time\n",
    "\n",
    "chrome_path = \"E:\\selenium_driver_chrome\\chromedriver.exe\" #chromedriver.exe執行檔所存在的路徑\n",
    "web = webdriver.Chrome(chrome_path)\n",
    "\n",
    "web.get('http://www.cwb.gov.tw/V7/')\n",
    "web.set_window_position(0,0) #瀏覽器位置\n",
    "web.set_window_size(700,700) #瀏覽器大小\n",
    "time.sleep(5)\n",
    "\n",
    "web.find_element_by_link_text('天氣預報').click() #點擊頁面上\"天氣預報\"的連結\n",
    "time.sleep(5)\n",
    "\n",
    "web.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PPT \n",
    "https://www.ptt.cc/bbs/e-shopping/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1533\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'base_url' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-82f233297286>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mpage\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mxrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtotal_page\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtotal_page\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m# xrange(起始值,結束值,step)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m     \u001b[0mtarget\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbase_url\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m     \u001b[1;31m#print(target)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[0mcurrent_page_raw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'base_url' is not defined"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "\n",
    "ptt_base_url = \"https://www.ptt.cc\"  #ppt主站\n",
    "travel_url = 'https://www.ptt.cc/bbs/travel/index{}.html' #ppt_travel版網址，頁碼浮動\n",
    "\n",
    "# \"\"\"爬取總頁數\"\"\"\n",
    "base_page_raw = requests.get(travel_url.format(''))\n",
    "base_page = BeautifulSoup(base_page_raw.text, 'html5lib')\n",
    "\n",
    "#[a.btn.wide]上一頁 > ['href']網址有頁碼 > 剖析[index]取index後的內容 > 在剖析[.]的內容, 取出上一頁頁數 > +1後即為最新一頁!!\n",
    "total_page = int(base_page\\\n",
    "             .select('a.btn.wide')[1]['href']\\\n",
    "             .split('index')[1]\\\n",
    "             .split('.')[0]) + 1\n",
    "print(total_page)\n",
    "\n",
    "for page in xrange(total_page-1, total_page-3, -1): # xrange(起始值,結束值,step)\n",
    "    target = base_url.format(page)\n",
    "    #print(target)\n",
    "    current_page_raw = requests.get(target)\n",
    "    current_page = BeautifulSoup(current_page_raw.text, 'html5lib')\n",
    "    \n",
    "#     \"\"\"列表 <list>\"\"\"\n",
    "    articles = current_page.select('div.r-ent') # List of Tags\n",
    "\n",
    "\n",
    "#     \"\"\"可以利用enumerate(list), 來取得list的index, value\"\"\"\n",
    "#     \"\"\"for index, article in articles:\"\"\"\n",
    "#     \"\"\"    print(index)\"\"\"\n",
    "#     \"\"\"    print(article)\"\"\"\n",
    "    \n",
    "    for index, article in enumerate(articles):\n",
    "        try:\n",
    "            article_dict = {}\n",
    "            #title = article.select('.title')[0].text.strip()\n",
    "            #author = article.select('.meta')[0].select('.author')[0].text.strip()\n",
    "            #date = article.select('.meta')[0].select('.date')[0].text.strip()\n",
    "            article_link = ptt_base_url + article.select('.title')[0].select('a')[0]['href']\n",
    "            print(article_link)\n",
    "            print(\"========================\")\n",
    "            \n",
    "            article_raw = requests.get(article_link)\n",
    "            article = BeautifulSoup(article_raw.text, 'html5lib')\n",
    "            article_meta_value = article.select(\".article-meta-value\")\n",
    "            #print(article_meta_value)\n",
    "            article_dict['title'] = article_meta_value[0].text\n",
    "            article_dict['author'] = article_meta_value[2].text\n",
    "            article_dict['date'] = article_meta_value[3].text\n",
    "            #print(title, author, date)\n",
    "            \n",
    "            article_dict['pushes'] = []\n",
    "            pushes = article.select('.push')\n",
    "            for push in pushes:\n",
    "                push_dict = {} # push_tag, push_userid, push_content, push_date\n",
    "                #print(push_first)\n",
    "                push_dict['push_tag'] = push.select('.push-tag')[0].text\n",
    "                push_dict['push_userid'] = push.select('.push-userid')[0].text\n",
    "                push_dict['push_content'] = push.select('.push-content')[0].text\n",
    "                push_dict['push_date'] = push.select('.push-ipdatetime')[0].text\n",
    "                article_dict['pushes'].append(push_dict)\n",
    "                #print(push)\n",
    "            \n",
    "            main_content = article.select('#main-content')[0]\n",
    "#             print(type(main_content.select('div')))\n",
    "#             print(help(main_content.select('div')[0].extract))\n",
    "            \n",
    "#             \"\"\"刪除所有main_content裡面的<div>\"\"\"\n",
    "            [s.extract() for s in main_content.select('div')]\n",
    "#             \"\"\"\n",
    "#             for s in main_content.select('div'):\n",
    "#                 print(type(s)) # s是一個Tag object <bs.Tag>\n",
    "#                 s.extract()\n",
    "#             \"\"\"\n",
    "            \n",
    "            article_dict['content'] = main_content.text.split(u'※ ')[0]\n",
    "            article_json = json.dumps(article_dict, ensure_ascii=False).encode('utf-8')\n",
    "            with open('C:\\Users\\BIG DATA\\Desktop\\ptt.txt'.format(page, index), 'w') as f:\n",
    "                f.write(article_json)\n",
    "            #print(article_dict)\n",
    "            \n",
    "            \n",
    "        except IndexError as e:\n",
    "            print(\"Article Deleted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# dir(requests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{u'data': [[1466899200000L, 0.899394], [1466812800000L, 0.899394], [1466726400000L, 0.89744], [1466640000000L, 0.880677], [1466553600000L, 0.886658], [1466467200000L, 0.884392], [1466380800000L, 0.882021], [1466294400000L, 0.886486], [1466208000000L, 0.886486], [1466121600000L, 0.888226], [1466035200000L, 0.890044], [1465948800000L, 0.890837], [1465862400000L, 0.888928], [1465776000000L, 0.887611], [1465689600000L, 0.888612], [1465603200000L, 0.888612], [1465516800000L, 0.885371], [1465430400000L, 0.879856], [1465344000000L, 0.87882], [1465257600000L, 0.880382], [1465171200000L, 0.880747], [1465084800000L, 0.879631], [1464998400000L, 0.879631], [1464912000000L, 0.891591], [1464825600000L, 0.894015], [1464739200000L, 0.896724], [1464652800000L, 0.897449], [1464566400000L, 0.898893], [1464480000000L, 0.899548]]}\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "res = requests.get('https://www.oanda.com/currency/historical-rates/')\n",
    "m = re.search('(\"data\":\\[\\[.*\\]\\])', res.text)\n",
    "data = json.loads('{' + m.group(1) + '}')\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
